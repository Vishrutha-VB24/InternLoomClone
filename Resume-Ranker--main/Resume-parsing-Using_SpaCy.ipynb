{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bharathkumar1011/resume-parsing-using-spacy?scriptVersionId=217944240\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install -qU langchain_community\n!pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:35:59.697798Z","iopub.execute_input":"2025-01-16T16:35:59.698263Z","iopub.status.idle":"2025-01-16T16:36:19.347352Z","shell.execute_reply.started":"2025-01-16T16:35:59.698221Z","shell.execute_reply":"2025-01-16T16:36:19.346076Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfplumber\n  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import spacy\nimport re\nimport pandas as pd\nfrom langchain_community.document_loaders import PDFPlumberLoader\nfrom spacy.matcher import Matcher","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:36:19.348788Z","iopub.execute_input":"2025-01-16T16:36:19.349271Z","iopub.status.idle":"2025-01-16T16:36:27.864583Z","shell.execute_reply.started":"2025-01-16T16:36:19.349232Z","shell.execute_reply":"2025-01-16T16:36:27.863622Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def extract_text_pdf(pdf_path):\n        loader = PDFPlumberLoader(pdf_path)\n        docs = loader.load()\n        text = ''\n        for doc in docs:\n            text += doc.page_content # Append extracted text\n        return text \n\n\ndef extract_name(nlp_text, matcher):\n    '''\n    Helper function to extract name from spacy nlp text\n\n    :param nlp_text: object of `spacy.tokens.doc.Doc`\n    :param matcher: object of `spacy.matcher.Matcher`\n    :return: string of full name\n    '''\n    pattern =  [{'POS': 'PROPN'}, {'POS': 'PROPN'}] \n    \"\"\"extrcted particular pattern variable\n        rather than imporing from a large data\n        \"\"\"\n    \n    matcher.add(\"NAME\", [pattern])# changed from \"matcher.add('NAME', None, *pattern)\"\n    \n    matches = matcher(nlp_text)\n    \n    for match_id, start, end in matches:\n        span = nlp_text[start:end]\n        return span.text\n\ndef extract_email(resume_text):\n    '''\n    Helper function to extract email id from text\n\n    :param text: plain text extracted from resume file\n    '''\n    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", resume_text)\n    if email:\n        try:\n            return email[0].split()[0].strip(';')\n        except IndexError:\n            return None\n\n\n\ndef extract_education_spacy(resume_text):\n    \"\"\"\n    Extracts the Education section from resume text using spaCy.\n    \n    :param resume_text: Plain resume text\n    :return: Extracted \"Education\" section as a string\n    \"\"\"\n\n    # Split the resume into lines\n    lines = resume_text.split(\"\\n\")\n\n    education_section = []\n    \n    # Extract lines after \"EDUCATION\" until the next section\n    for line in lines:\n        if education_section and re.search(r\"\\b(project|skills|work experience|certifications)\\b\", line, re.IGNORECASE):  \n            break \n    \n        if re.search(r\"\\b(education)\\b\", line, re.IGNORECASE) or education_section:  \n            education_section.append(line.strip())\n    \n    education_text = \"\\n\".join(education_section)\n\n    education_text = education_text.replace('\\\\n', ' ').replace('\\n', ' ').strip()\n\n    return education_text\n\n\n\n\ndef extract_skills(nlp_text, noun_chunks):\n    '''\n    Helper function to extract skills from spacy nlp text\n\n    :param nlp_text: object of `spacy.tokens.doc.Doc`\n    :param noun_chunks: noun chunks extracted from nlp text\n    :return: list of skills extracted\n    '''\n    tokens = [token.text for token in nlp_text if not token.is_stop]\n    \n    # if noun_chunks is None:\n    #     noun_chunks = list(nlp_text.noun_chunks)\n\n    \n    url = \"https://raw.githubusercontent.com/OmkarPathak/ResumeParser/refs/heads/master/resume_parser/resume_parser/skills.csv\"\n    df = pd.read_csv(url, index_col=0)\n    data = df\n    \n    skills = list(data.columns.values)\n    \n    skillset = []\n    # check for one-grams\n    for token in tokens:\n        if token.lower() in skills:\n            skillset.append(token)\n    \n    # check for bi-grams and tri-grams\n    for token in noun_chunks:\n        token = token.text.lower().strip()\n        if token in skills:\n            skillset.append(token)\n    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n\n\ndef extract_experience_spacy(resume_text):\n    '''\n    Extracts the experience section from resume text using spaCy.\n    Also extracts job titles, company names, and dates.\n    \n    :param resume_text: Plain resume text\n    :return: Extracted \"Experience\" section as a string\n    '''\n\n\n    # Step 1: Extract the \"Experience\" section based on headers\n    lines = resume_text.split(\"\\n\")\n    experience_section = []\n    capture = False\n\n   # Step 1: Start capturing after \"WORK EXPERIENCE\" or similar headers\n    for line in lines:\n        if re.search(r\"\\b(experience|work experience|employment history)\\b\", line, re.IGNORECASE):  # Detect section start\n            capture = True\n        elif capture and re.search(r\"\\b(education|skills|projects)\\b\", line, re.IGNORECASE):  # Stop at next section\n            break\n        if capture:\n            experience_section.append(line.strip())\n\n    experience_text = \"\\n\".join(experience_section)\n    experience_text = experience_text.replace('\\\\n', ' ').replace('\\n', ' ').strip()\n\n    # Step 2: Extract structured entities using spaCy\n    experience_doc = nlp(experience_text)\n    extracted_info = {\n        \"Job Titles\": [],\n        \"Companies\": [],\n        \"Dates\": []\n    }\n    return experience_text\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:38:01.011827Z","iopub.execute_input":"2025-01-16T16:38:01.01227Z","iopub.status.idle":"2025-01-16T16:38:01.0272Z","shell.execute_reply.started":"2025-01-16T16:38:01.012237Z","shell.execute_reply":"2025-01-16T16:38:01.026261Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/barath-resume/Bharath_Kumar_Resume.pdf\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:38:05.182077Z","iopub.execute_input":"2025-01-16T16:38:05.18256Z","iopub.status.idle":"2025-01-16T16:38:05.187736Z","shell.execute_reply.started":"2025-01-16T16:38:05.182518Z","shell.execute_reply":"2025-01-16T16:38:05.186489Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"text = extract_text_pdf(pdf_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:38:05.397184Z","iopub.execute_input":"2025-01-16T16:38:05.397693Z","iopub.status.idle":"2025-01-16T16:38:05.660453Z","shell.execute_reply.started":"2025-01-16T16:38:05.397646Z","shell.execute_reply":"2025-01-16T16:38:05.659489Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nnlp_text = nlp(text)\nnoun_chunks = list(nlp_text.noun_chunks)\nmatcher = Matcher(nlp.vocab)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:38:06.588511Z","iopub.execute_input":"2025-01-16T16:38:06.589588Z","iopub.status.idle":"2025-01-16T16:38:07.719843Z","shell.execute_reply.started":"2025-01-16T16:38:06.589517Z","shell.execute_reply":"2025-01-16T16:38:07.718725Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"output = {\n    \"Name\": extract_name(nlp_text, matcher),\n    \"Email\": extract_email(text),\n    \"Skills\":extract_skills(nlp_text, noun_chunks),\n    \"Education\": extract_education_spacy(text),\n    \"Experience\": extract_experience_spacy(text),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:38:09.738508Z","iopub.execute_input":"2025-01-16T16:38:09.739033Z","iopub.status.idle":"2025-01-16T16:38:10.264733Z","shell.execute_reply.started":"2025-01-16T16:38:09.738945Z","shell.execute_reply":"2025-01-16T16:38:10.263454Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:39:06.943064Z","iopub.execute_input":"2025-01-16T16:39:06.943515Z","iopub.status.idle":"2025-01-16T16:39:06.949857Z","shell.execute_reply.started":"2025-01-16T16:39:06.943478Z","shell.execute_reply":"2025-01-16T16:39:06.94844Z"}},"outputs":[{"name":"stdout","text":"{'Name': 'Bharath Kumar', 'Email': 'bharathkumar1011@gmail.com', 'Skills': ['Modeling', 'Python', 'Analysis', 'Analyze', 'Engineering', 'Communication', 'Sql', 'Data quality', 'Data analysis', 'Programming', 'Jupyter', 'Statistical analysis', 'Analytics', 'Technical', 'Reports', 'Database', 'Pattern', 'Datasets', 'Etl', 'Excel'], 'Education': 'Education B.Tech in Aeronautical Engineering Institute of Aeronautical Engineering 2014 - 2018 GPA: 6.18/10', 'Experience': 'Results-driven Data Scientist with two years of experience in data analysis, predictive modeling, and data visualization. Passionate about leveraging data-driven insights to optimize business strategies and enhance decision-making processes. Experience Data Scientist XYZ Company, Hyderabad January 2022 - Present - Developed predictive models to analyze customer behavior and optimize business strategies. - Performed exploratory data analysis (EDA) and data cleaning to improve data quality. - Designed and maintained ETL pipelines to streamline data processing. - Collaborated with cross-functional teams to deliver data-driven insights. Junior Data Analyst ABC Analytics, Hyderabad January 2020 - December 2021 - Conducted statistical analysis and data visualization to support business decisions. - Created dashboards and reports using Excel and Python. - Assisted in implementing machine learning models for pattern recognition. - Worked with large datasets and ensured data integrity.'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"for k,v in output.items():\n    print(k,v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:39:11.723505Z","iopub.execute_input":"2025-01-16T16:39:11.723956Z","iopub.status.idle":"2025-01-16T16:39:11.732367Z","shell.execute_reply.started":"2025-01-16T16:39:11.723914Z","shell.execute_reply":"2025-01-16T16:39:11.731102Z"}},"outputs":[{"name":"stdout","text":"Name Bharath Kumar\nEmail bharathkumar1011@gmail.com\nSkills ['Modeling', 'Python', 'Analysis', 'Analyze', 'Engineering', 'Communication', 'Sql', 'Data quality', 'Data analysis', 'Programming', 'Jupyter', 'Statistical analysis', 'Analytics', 'Technical', 'Reports', 'Database', 'Pattern', 'Datasets', 'Etl', 'Excel']\nEducation Education B.Tech in Aeronautical Engineering Institute of Aeronautical Engineering 2014 - 2018 GPA: 6.18/10\nExperience Results-driven Data Scientist with two years of experience in data analysis, predictive modeling, and data visualization. Passionate about leveraging data-driven insights to optimize business strategies and enhance decision-making processes. Experience Data Scientist XYZ Company, Hyderabad January 2022 - Present - Developed predictive models to analyze customer behavior and optimize business strategies. - Performed exploratory data analysis (EDA) and data cleaning to improve data quality. - Designed and maintained ETL pipelines to streamline data processing. - Collaborated with cross-functional teams to deliver data-driven insights. Junior Data Analyst ABC Analytics, Hyderabad January 2020 - December 2021 - Conducted statistical analysis and data visualization to support business decisions. - Created dashboards and reports using Excel and Python. - Assisted in implementing machine learning models for pattern recognition. - Worked with large datasets and ensured data integrity.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}