{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10572034,"sourceType":"datasetVersion","datasetId":6541965}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qU langchain_community\n!pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:27:22.358606Z","iopub.execute_input":"2025-01-25T07:27:22.358970Z","iopub.status.idle":"2025-01-25T07:27:41.267082Z","shell.execute_reply.started":"2025-01-25T07:27:22.358943Z","shell.execute_reply":"2025-01-25T07:27:41.265794Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfplumber\n  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\nfrom langchain_community.document_loaders import PDFPlumberLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:27:41.268499Z","iopub.execute_input":"2025-01-25T07:27:41.268794Z","iopub.status.idle":"2025-01-25T07:27:42.918758Z","shell.execute_reply.started":"2025-01-25T07:27:41.268768Z","shell.execute_reply":"2025-01-25T07:27:42.917414Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/test-res-regex/Steve Sun - Resume (2).pdf\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:27:42.920488Z","iopub.execute_input":"2025-01-25T07:27:42.920946Z","iopub.status.idle":"2025-01-25T07:27:42.925212Z","shell.execute_reply.started":"2025-01-25T07:27:42.920915Z","shell.execute_reply":"2025-01-25T07:27:42.924156Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def extract_text_pdf(pdf_path):\n        loader = PDFPlumberLoader(pdf_path)\n        docs = loader.load()\n        text = ''\n        for doc in docs:\n            text += doc.page_content # Append extracted text\n        return text \n\n\ndef extract_name_from_resume(text):\n    name = None\n\n    # Use regex pattern to find a potential name\n    pattern = r\"(\\b[A-Z][a-z]+\\b)\\s(\\b[A-Z][a-z]+\\b)\"\n    match = re.search(pattern, text)\n    if match:\n        name = match.group()\n\n    return name\n\ndef extract_email_from_resume(text):\n    email = None\n\n    # Use regex pattern to find a potential email address\n    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n    match = re.search(pattern, text)\n    if match:\n        email = match.group()\n\n    return email\n\n\ndef extract_skills_from_resume(text, skills_list):\n    skills = []\n\n    # Search for skills in the resume text\n    for skill in skills_list:\n        pattern = r\"\\b{}\\b\".format(re.escape(skill))\n        match = re.search(pattern, text, re.IGNORECASE)\n        if match:\n            skills.append(skill)\n\n    return skills\n\n\ndef extract_education_details(text):\n\n    pattern = r\"(?P<university>[\\w\\s,&]+(?:University|College|Institute|Academy))\\n(?P<degree>.+?)\\s(?:-\\s(?P<gpa>\\d\\.\\d{1,2}\\sGPA))?\\s(?P<start_date>\\w+\\s\\d{4})\\s(?:[-–]\\s(?P<end_date>\\w+\\s\\d{4}))?\"\n\n    matches = re.finditer(pattern, text)\n    \n    education_dict = {\n        \"University\": [],\n        \"Degree\": [],\n        \"GPA\": [],\n        \"Start Date\": [],\n        \"End Date\": [],\n    }\n    \n    # Extract and organize data\n    for match in matches:\n        education_dict[\"University\"].append(match.group(\"university\").strip())\n        education_dict[\"Degree\"].append(match.group(\"degree\").strip())\n        education_dict[\"GPA\"].append(match.group(\"gpa\").strip() if match.group(\"gpa\") else \"N/A\")\n        education_dict[\"Start Date\"].append(match.group(\"start_date\").strip())\n        education_dict[\"End Date\"].append(match.group(\"end_date\").strip() if match.group(\"end_date\") else \"Present\")\n    \n    return education_dict\n\n\ndef extracting_experirnce(text):\n        \n    matches = re.search(pattern, text, re.DOTALL)\n    \n    if matches:\n        work = matches.group(1).strip()\n        return work\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:42:47.940423Z","iopub.execute_input":"2025-01-25T07:42:47.940761Z","iopub.status.idle":"2025-01-25T07:42:47.952352Z","shell.execute_reply.started":"2025-01-25T07:42:47.940735Z","shell.execute_reply":"2025-01-25T07:42:47.951145Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"text = extract_text_pdf(pdf_path)\nskills_list = ['Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Project Management', 'Deep Learning', 'SQL', 'Tableau','AI',\n'Data Visualization','Statistical Analysis','Big Data','Cloud Technologies''Problem-Solving','Critical Thinking',\n'Storytelling']\npattern = r\"WORK EXPERIENCE\\n(.*?)\\nEDUCATION\"\n\n# below is the general pattern for the experience extraction\n# pattern =  r\"(?i)(work\\s*experience|professional\\s*experience|employment\\s*history)[\\s\\S]*?(?=(education|skills|projects|$))\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:56:08.718377Z","iopub.execute_input":"2025-01-25T07:56:08.718740Z","iopub.status.idle":"2025-01-25T07:56:08.883549Z","shell.execute_reply.started":"2025-01-25T07:56:08.718713Z","shell.execute_reply":"2025-01-25T07:56:08.882379Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"output = {\n    \"Name\": extract_name_from_resume(text),\n    \"Email\": extract_email_from_resume(text),\n    \"Skills\":extract_skills_from_resume(text, skills_list),\n    \"Education\": extract_education_details(text),\n    \"Experience\": extracting_experirnce(text),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:48:31.724172Z","iopub.execute_input":"2025-01-25T07:48:31.724591Z","iopub.status.idle":"2025-01-25T07:48:31.734851Z","shell.execute_reply.started":"2025-01-25T07:48:31.724558Z","shell.execute_reply":"2025-01-25T07:48:31.733884Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T07:49:44.664289Z","iopub.execute_input":"2025-01-25T07:49:44.664702Z","iopub.status.idle":"2025-01-25T07:49:44.671318Z","shell.execute_reply.started":"2025-01-25T07:49:44.664665Z","shell.execute_reply":"2025-01-25T07:49:44.669390Z"}},"outputs":[{"name":"stdout","text":"{'Name': 'Steve Sun', 'Email': 'stevesun1245@gmail.com', 'Skills': ['Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Deep Learning', 'SQL', 'AI', 'Data Visualization', 'Statistical Analysis', 'Big Data', 'Critical Thinking', 'Storytelling'], 'Education': {'University': ['EDUCATION\\nSkyline University'], 'Degree': ['Master of Science in Data Science'], 'GPA': ['3.81 GPA'], 'Start Date': ['August 2018'], 'End Date': ['May 2020']}, 'Experience': {'work': ['DataNova Insights\\nData Scientist March 2021 – Present\\n• Developed and deployed machine learning models to optimize customer retention, increasing\\nengagement by 15%.\\n• Conducted exploratory data analysis (EDA) and statistical testing to derive actionable business\\ninsights.\\n• Built scalable ETL pipelines to process large datasets using Python and SQL.\\n• Collaborated with cross-functional teams to improve decision-making through predictive analytics.\\nNeural Sphere Labs\\nData Scientist June 2019 – December 2023\\n• Designed and implemented deep learning models for image classification, improving accuracy by\\n20%.\\n• Automated data preprocessing and feature engineering workflows using Python and Pandas.\\n• Created interactive dashboards in Power BI to visualize key performance indicators (KPIs).\\n• Partnered with engineers to deploy ML models into production, ensuring seamless integration.']}}\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}