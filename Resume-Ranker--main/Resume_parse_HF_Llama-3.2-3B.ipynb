{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10507973,"sourceType":"datasetVersion","datasetId":6505385}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bharathkumar1011/resume-parse-hf-llama-3-2-3b?scriptVersionId=219013160\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# First, install required packages\n!pip install langchain langchain-community langchain-core langchain_huggingface transformers pdfplumber accelerate --upgrade --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:13:22.872314Z","iopub.execute_input":"2025-01-24T05:13:22.872533Z","iopub.status.idle":"2025-01-24T05:13:42.066796Z","shell.execute_reply.started":"2025-01-24T05:13:22.872509Z","shell.execute_reply":"2025-01-24T05:13:42.065665Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nfrom langchain_community.document_loaders import PDFPlumberLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom langchain_huggingface.llms import HuggingFacePipeline\nfrom langchain_core.prompts import ChatPromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:14:35.368478Z","iopub.execute_input":"2025-01-24T05:14:35.368819Z","iopub.status.idle":"2025-01-24T05:14:55.754199Z","shell.execute_reply.started":"2025-01-24T05:14:35.368791Z","shell.execute_reply":"2025-01-24T05:14:55.753481Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def extract_text_pdf(pdf_path):\n        loader = PDFPlumberLoader(pdf_path)\n        docs = loader.load()\n        text = ''\n        for doc in docs:\n            text += doc.page_content # Append extracted text\n        return text \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:14:55.755236Z","iopub.execute_input":"2025-01-24T05:14:55.755831Z","iopub.status.idle":"2025-01-24T05:14:55.759681Z","shell.execute_reply.started":"2025-01-24T05:14:55.755807Z","shell.execute_reply":"2025-01-24T05:14:55.758877Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"system_prompt = \"\"\"You are an AI assistant designed to extract structured resume data.\n                   Always respond with a strictly valid JSON object. Use `null` for missing values,\n                   ensuring compliance with JSON standards. Do not include explanations,\n                   comments, or any additional text outside the JSON structure.\n                \"\"\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:17.469183Z","iopub.execute_input":"2025-01-24T05:15:17.469481Z","iopub.status.idle":"2025-01-24T05:15:17.473247Z","shell.execute_reply.started":"2025-01-24T05:15:17.469459Z","shell.execute_reply":"2025-01-24T05:15:17.472388Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# human_prompt = \"\"\"{\n#   \"instruction\": \"You are an expert assistant for parsing resumes into structured JSON format.\",\n#   \"task\": \"Extract key details from the resume text provided below and output a valid JSON object with the following fields:\",\n#   \"fields\": [\n#     \"Name\",\n#     \"Email ID\",\n#     \"Skills\",\n#     \"Education\",\n#     \"Experience\",\n#   ],\n#   \"notes\": [\n#     \"Use `null` if a field is not found.\",\n#     \"Ensure the JSON is valid and well-structured.\",\n#     \"Do not include any explanations or extra text.\"\n#   ],\n#   \"example\": {\n#     \"Name\": \"John Doe\",\n#     \"Contact Information\": \"john.doe@example.com, +1-234-567-890\",\n#     \"Summary\": \"Experienced software developer specializing in AI solutions.\",\n#     \"Skills\": [\"Python\", \"Machine Learning\", \"NLP\", \"Django\"],\n#     \"Education\": \"B.Sc. in Computer Science, XYZ University\",\n#     \"Experience\": [\n#       {\n#         \"Company\": \"Tech Solutions Inc.\",\n#         \"Role\": \"Software Developer\",\n#         \"Duration\": \"Jan 2020 - Dec 2022\",\n#         \"Responsibilities\": [\"Developed web applications\", \"Integrated AI models\"]\n#       }\n#     ],\n#     \"Certifications\": [\"AWS Certified Solutions Architect\"],\n#     \"Projects\": [\"Resume Parsing Project using LLaMA and LangChain\"],\n#     \"Languages\": [\"English\", \"Spanish\"],\n#     \"Achievements\": [\"Employee of the Month (March 2021)\"]\n#   }\n# }\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:17.688292Z","iopub.execute_input":"2025-01-24T05:15:17.68858Z","iopub.status.idle":"2025-01-24T05:15:17.692176Z","shell.execute_reply.started":"2025-01-24T05:15:17.688558Z","shell.execute_reply":"2025-01-24T05:15:17.691361Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"human_prompt = \"\"\"\n             **Task:** Extract key information from the following resume text.\n\n            **Resume Text:**\n            {context}\n\n            **Instructions:**\n            Please extract the following information and format it in a clear structure:\n\n            1. **Contact Information:**\n            - Name:\n            - Email:\n            - Phone Number:\n            - Website/Portfolio/LinkedIn:\n            - Github Profile:\n\n            2. **Education:**\n            - Institution Name:\n            - Degree:\n            - Graduation Date:\n\n            3. **Experience:**\n            - Job Title:\n            - Company Name:\n            - Location:\n            - Dates of Employment:\n            - Description:\n\n            5. **Skills:**\n            - Skills:\n\n            **Question:**\n            Extract this information as a structured and valid JSON object. Use `null` for missing or unavailable values.\n        \"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:21.470876Z","iopub.execute_input":"2025-01-24T05:15:21.471188Z","iopub.status.idle":"2025-01-24T05:15:21.475209Z","shell.execute_reply.started":"2025-01-24T05:15:21.471166Z","shell.execute_reply":"2025-01-24T05:15:21.474299Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/test-resumes/Steve Sun - Resume (2).pdf\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:24.49842Z","iopub.execute_input":"2025-01-24T05:15:24.498719Z","iopub.status.idle":"2025-01-24T05:15:24.502499Z","shell.execute_reply.started":"2025-01-24T05:15:24.498697Z","shell.execute_reply":"2025-01-24T05:15:24.501573Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"context = extract_text_pdf(pdf_path)\nprint(context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:26.267559Z","iopub.execute_input":"2025-01-24T05:15:26.267905Z","iopub.status.idle":"2025-01-24T05:15:26.436189Z","shell.execute_reply.started":"2025-01-24T05:15:26.267879Z","shell.execute_reply":"2025-01-24T05:15:26.435253Z"}},"outputs":[{"name":"stdout","text":"Steve Sun\nResults-driven professional with expertise in data analysis, machine learning, and statistical modeling.\nPassionate about transforming complex data into actionable insights to drive innovation and business\nimpact.\nstevesun1245@gmail.com (123)456789 Hyderabad linkedin.com/in/stevesun\nWORK EXPERIENCE\nDataNova Insights\nData Scientist March 2021 – Present\n• Developed and deployed machine learning models to optimize customer retention, increasing\nengagement by 15%.\n• Conducted exploratory data analysis (EDA) and statistical testing to derive actionable business\ninsights.\n• Built scalable ETL pipelines to process large datasets using Python and SQL.\n• Collaborated with cross-functional teams to improve decision-making through predictive analytics.\nNeural Sphere Labs\nData Scientist June 2019 – December 2023\n• Designed and implemented deep learning models for image classification, improving accuracy by\n20%.\n• Automated data preprocessing and feature engineering workflows using Python and Pandas.\n• Created interactive dashboards in Power BI to visualize key performance indicators (KPIs).\n• Partnered with engineers to deploy ML models into production, ensuring seamless integration.\nEDUCATION\nSkyline University\nMaster of Science in Data Science - 3.81 GPA August 2018 – May 2020\nPROJECT\nResume Parser using NLP December 2022\n• Developed an AI-powered resume parser using Natural Language Processing (NLP) to extract\nkey information such as name, contact details, skills, experience, and education from resumes in\nvarious formats (PDF, DOCX).\nSKILLS\n• Python\n• SQL\n• Machine Learning\n• AI\n• Data Visualization\n• Statistical Analysis\n• Big Data\n• Cloud Technologies\n• Problem-Solving\n• Critical Thinking\n• Communication\n• Storytelling\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"template = ChatPromptTemplate.from_messages([\n    (\"system\", system_prompt),\n    (\"human\", human_prompt),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:29.467104Z","iopub.execute_input":"2025-01-24T05:15:29.467387Z","iopub.status.idle":"2025-01-24T05:15:29.471588Z","shell.execute_reply.started":"2025-01-24T05:15:29.467367Z","shell.execute_reply":"2025-01-24T05:15:29.470672Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"question = \"Extract key information from this resume.\"\ncomplete_prompt = template.format_messages(context=context, question=question)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:29.773673Z","iopub.execute_input":"2025-01-24T05:15:29.773959Z","iopub.status.idle":"2025-01-24T05:15:29.777857Z","shell.execute_reply.started":"2025-01-24T05:15:29.773937Z","shell.execute_reply":"2025-01-24T05:15:29.776965Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"complete_prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:22:58.214203Z","iopub.execute_input":"2025-01-24T05:22:58.214511Z","iopub.status.idle":"2025-01-24T05:22:58.219953Z","shell.execute_reply.started":"2025-01-24T05:22:58.214486Z","shell.execute_reply":"2025-01-24T05:22:58.219076Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[SystemMessage(content='You are an AI assistant designed to extract structured resume data.\\n                   Always respond with a strictly valid JSON object. Use `null` for missing values,\\n                   ensuring compliance with JSON standards. Do not include explanations,\\n                   comments, or any additional text outside the JSON structure.\\n                ', additional_kwargs={}, response_metadata={}),\n HumanMessage(content='\\n             **Task:** Extract key information from the following resume text.\\n\\n            **Resume Text:**\\n            Steve Sun\\nResults-driven professional with expertise in data analysis, machine learning, and statistical modeling.\\nPassionate about transforming complex data into actionable insights to drive innovation and business\\nimpact.\\nstevesun1245@gmail.com (123)456789 Hyderabad linkedin.com/in/stevesun\\nWORK EXPERIENCE\\nDataNova Insights\\nData Scientist March 2021 – Present\\n• Developed and deployed machine learning models to optimize customer retention, increasing\\nengagement by 15%.\\n• Conducted exploratory data analysis (EDA) and statistical testing to derive actionable business\\ninsights.\\n• Built scalable ETL pipelines to process large datasets using Python and SQL.\\n• Collaborated with cross-functional teams to improve decision-making through predictive analytics.\\nNeural Sphere Labs\\nData Scientist June 2019 – December 2023\\n• Designed and implemented deep learning models for image classification, improving accuracy by\\n20%.\\n• Automated data preprocessing and feature engineering workflows using Python and Pandas.\\n• Created interactive dashboards in Power BI to visualize key performance indicators (KPIs).\\n• Partnered with engineers to deploy ML models into production, ensuring seamless integration.\\nEDUCATION\\nSkyline University\\nMaster of Science in Data Science - 3.81 GPA August 2018 – May 2020\\nPROJECT\\nResume Parser using NLP December 2022\\n• Developed an AI-powered resume parser using Natural Language Processing (NLP) to extract\\nkey information such as name, contact details, skills, experience, and education from resumes in\\nvarious formats (PDF, DOCX).\\nSKILLS\\n• Python\\n• SQL\\n• Machine Learning\\n• AI\\n• Data Visualization\\n• Statistical Analysis\\n• Big Data\\n• Cloud Technologies\\n• Problem-Solving\\n• Critical Thinking\\n• Communication\\n• Storytelling\\n\\n\\n            **Instructions:**\\n            Please extract the following information and format it in a clear structure:\\n\\n            1. **Contact Information:**\\n            - Name:\\n            - Email:\\n            - Phone Number:\\n            - Website/Portfolio/LinkedIn:\\n            - Github Profile:\\n\\n            2. **Education:**\\n            - Institution Name:\\n            - Degree:\\n            - Graduation Date:\\n\\n            3. **Experience:**\\n            - Job Title:\\n            - Company Name:\\n            - Location:\\n            - Dates of Employment:\\n            - Description:\\n\\n            5. **Skills:**\\n            - Skills:\\n\\n            **Question:**\\n            Extract this information as a structured and valid JSON object. Use `null` for missing or unavailable values.\\n        ', additional_kwargs={}, response_metadata={})]"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"### With the bullet point symbol in the complete prompt, the response is cutting off and not giving the whole answer. So, I replaced the bullet point symbol with space, which solved the JSON format structured output problem with the LLaMA invoke response.\n\n# What I learned:\n### -The complete prompt should not contain any bullet points or any type of cutting symbols to perform better.\n","metadata":{}},{"cell_type":"code","source":"# Assuming complete_prompt is a list of objects that have a 'content' attribute\ncomplete_prompt = [text.content.replace(\"•\", \" \") for text in complete_prompt]\n\n# Output the result\nprint(complete_prompt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:27:38.168359Z","iopub.execute_input":"2025-01-24T05:27:38.168789Z","iopub.status.idle":"2025-01-24T05:27:38.174269Z","shell.execute_reply.started":"2025-01-24T05:27:38.16874Z","shell.execute_reply":"2025-01-24T05:27:38.173335Z"}},"outputs":[{"name":"stdout","text":"['You are an AI assistant designed to extract structured resume data.\\n                   Always respond with a strictly valid JSON object. Use `null` for missing values,\\n                   ensuring compliance with JSON standards. Do not include explanations,\\n                   comments, or any additional text outside the JSON structure.\\n                ', '\\n             **Task:** Extract key information from the following resume text.\\n\\n            **Resume Text:**\\n            Steve Sun\\nResults-driven professional with expertise in data analysis, machine learning, and statistical modeling.\\nPassionate about transforming complex data into actionable insights to drive innovation and business\\nimpact.\\nstevesun1245@gmail.com (123)456789 Hyderabad linkedin.com/in/stevesun\\nWORK EXPERIENCE\\nDataNova Insights\\nData Scientist March 2021 – Present\\n  Developed and deployed machine learning models to optimize customer retention, increasing\\nengagement by 15%.\\n  Conducted exploratory data analysis (EDA) and statistical testing to derive actionable business\\ninsights.\\n  Built scalable ETL pipelines to process large datasets using Python and SQL.\\n  Collaborated with cross-functional teams to improve decision-making through predictive analytics.\\nNeural Sphere Labs\\nData Scientist June 2019 – December 2023\\n  Designed and implemented deep learning models for image classification, improving accuracy by\\n20%.\\n  Automated data preprocessing and feature engineering workflows using Python and Pandas.\\n  Created interactive dashboards in Power BI to visualize key performance indicators (KPIs).\\n  Partnered with engineers to deploy ML models into production, ensuring seamless integration.\\nEDUCATION\\nSkyline University\\nMaster of Science in Data Science - 3.81 GPA August 2018 – May 2020\\nPROJECT\\nResume Parser using NLP December 2022\\n  Developed an AI-powered resume parser using Natural Language Processing (NLP) to extract\\nkey information such as name, contact details, skills, experience, and education from resumes in\\nvarious formats (PDF, DOCX).\\nSKILLS\\n  Python\\n  SQL\\n  Machine Learning\\n  AI\\n  Data Visualization\\n  Statistical Analysis\\n  Big Data\\n  Cloud Technologies\\n  Problem-Solving\\n  Critical Thinking\\n  Communication\\n  Storytelling\\n\\n\\n            **Instructions:**\\n            Please extract the following information and format it in a clear structure:\\n\\n            1. **Contact Information:**\\n            - Name:\\n            - Email:\\n            - Phone Number:\\n            - Website/Portfolio/LinkedIn:\\n            - Github Profile:\\n\\n            2. **Education:**\\n            - Institution Name:\\n            - Degree:\\n            - Graduation Date:\\n\\n            3. **Experience:**\\n            - Job Title:\\n            - Company Name:\\n            - Location:\\n            - Dates of Employment:\\n            - Description:\\n\\n            5. **Skills:**\\n            - Skills:\\n\\n            **Question:**\\n            Extract this information as a structured and valid JSON object. Use `null` for missing or unavailable values.\\n        ']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:15:35.663796Z","iopub.execute_input":"2025-01-24T05:15:35.664263Z","iopub.status.idle":"2025-01-24T05:15:35.685254Z","shell.execute_reply.started":"2025-01-24T05:15:35.664225Z","shell.execute_reply":"2025-01-24T05:15:35.684142Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41dac3d5584d418aad5f4df5a393fd07"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\nmodel = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\ntask = \"text-generation\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:16:03.553625Z","iopub.execute_input":"2025-01-24T05:16:03.554151Z","iopub.status.idle":"2025-01-24T05:18:47.003648Z","shell.execute_reply.started":"2025-01-24T05:16:03.55411Z","shell.execute_reply":"2025-01-24T05:18:47.002646Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e363b10bf59d4b928315bc9e6335e6bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c2eed5d2e8b4aeaa37cea58cf165287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0910f723f56a4ed0984dd0598b245d44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfb012cba6f043699aab8014548dac18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"059ed19220c742de8f2a31c989f0c6ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbfc34098b134751950d5b8029014e76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d79e65dd1ca54d629d5e9de63246e9a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60eb1dbc9e94716bcf15dc950676e6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc700ee7ac2491d81372a5e382bbb7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c429672d5c2647f68fa9410767a713d6"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"pipe = pipeline(\n    task,\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=512,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:18:49.849065Z","iopub.execute_input":"2025-01-24T05:18:49.849349Z","iopub.status.idle":"2025-01-24T05:18:53.994132Z","shell.execute_reply.started":"2025-01-24T05:18:49.849328Z","shell.execute_reply":"2025-01-24T05:18:53.99342Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=pipe)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:18:53.995018Z","iopub.execute_input":"2025-01-24T05:18:53.995251Z","iopub.status.idle":"2025-01-24T05:18:54.003058Z","shell.execute_reply.started":"2025-01-24T05:18:53.995231Z","shell.execute_reply":"2025-01-24T05:18:54.002141Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"%%time\nresponse = llm.invoke(complete_prompt, skip_prompt=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:27:53.368219Z","iopub.execute_input":"2025-01-24T05:27:53.368518Z","iopub.status.idle":"2025-01-24T05:28:10.120047Z","shell.execute_reply.started":"2025-01-24T05:27:53.368496Z","shell.execute_reply":"2025-01-24T05:28:10.119292Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 16.8 s, sys: 4.1 ms, total: 16.8 s\nWall time: 16.7 s\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T05:28:10.121044Z","iopub.execute_input":"2025-01-24T05:28:10.121331Z","iopub.status.idle":"2025-01-24T05:28:10.125473Z","shell.execute_reply.started":"2025-01-24T05:28:10.121309Z","shell.execute_reply":"2025-01-24T05:28:10.124689Z"}},"outputs":[{"name":"stdout","text":"\n\n\n            {\n                \"name\": \"Steve Sun\",\n                \"email\": \"stevesun1245@gmail.com\",\n                \"phone\": null,\n                \"website\": null,\n                \"linkedin\": \"linkedin.com/in/stevesun\",\n                \"github\": null,\n                \"education\": {\n                    \"institution\": \"Skyline University\",\n                    \"degree\": \"Master of Science in Data Science\",\n                    \"graduationDate\": \"May 2020\"\n                },\n                \"experience\": [\n                    {\n                        \"title\": \"Data Scientist\",\n                        \"company\": \"DataNova Insights\",\n                        \"location\": \"Hyderabad\",\n                        \"dates\": \"March 2021 – Present\",\n                        \"description\": \"Developed and deployed machine learning models to optimize customer retention, increasing engagement by 15%. Conducted exploratory data analysis (EDA) and statistical testing to derive actionable business insights. Built scalable ETL pipelines to process large datasets using Python and SQL. Collaborated with cross-functional teams to improve decision-making through predictive analytics.\"\n                    },\n                    {\n                        \"title\": \"Data Scientist\",\n                        \"company\": \"Neural Sphere Labs\",\n                        \"location\": \"Hyderabad\",\n                        \"dates\": \"June 2019 – December 2023\",\n                        \"description\": \"Designed and implemented deep learning models for image classification, improving accuracy by 20%. Automated data preprocessing and feature engineering workflows using Python and Pandas. Created interactive dashboards in Power BI to visualize key performance indicators (KPIs). Partnered with engineers to deploy ML models into production, ensuring seamless integration.\"\n                    }\n                ],\n                \"skills\": [\n                    \"Python\",\n                    \"SQL\",\n                    \"Machine Learning\",\n                    \"AI\",\n                    \"Data Visualization\",\n                    \"Statistical Analysis\",\n                    \"Big Data\",\n                    \"Cloud Technologies\",\n                    \"Problem-Solving\",\n                    \"Critical Thinking\",\n                    \"Communication\",\n                    \"Storytelling\"\n                ]\n            }\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}